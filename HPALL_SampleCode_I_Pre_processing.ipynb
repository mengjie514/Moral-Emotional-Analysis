{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7HGheimymKEOFEQ7Vtn6V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mengjie514/Moral-Emotional-Analysis/blob/main/HPALL_SampleCode_I_Pre_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEhKN44JnalT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93d49eea-87a1-4941-ddb9-49b67cd09ca2"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/PSIV\")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "\n",
        "import json\n",
        "\n",
        "data_list = []\n",
        "tweets_info_temp = {\n",
        "    'Corpus':'',\n",
        "    'tweet_id':0,\n",
        "    'tweet_text':'',\n",
        "    'annotation_0':'',\n",
        "    'annotation_1':'',\n",
        "    'annotation_2':'',\n",
        "    'annotation_3':'',\n",
        "    'annotation_4':'',\n",
        "    'annotation_5':'',\n",
        "    'annotation_6':'',\n",
        "    'annotation_7':'',\n",
        "}\n",
        "\n",
        "with open('MFTC_V4_text.json','r') as f:\n",
        "    data = json.loads(f.read())\n",
        "\n",
        "    for corpus_index in range(len(data)):\n",
        "        Tweets = data[corpus_index]['Tweets']\n",
        "\n",
        "        for tweet in Tweets:\n",
        "            tweet_info = tweets_info_temp.copy()\n",
        "            tweet_info['Corpus'] = data[corpus_index]['Corpus']\n",
        "            tweet_info['tweet_id'] = tweet['tweet_id']\n",
        "            tweet_info['tweet_text'] = tweet['tweet_text']\n",
        "\n",
        "            annotation_count = 0\n",
        "            for item in tweet['annotations']:\n",
        "                tweet_info[f'annotation_{annotation_count}'] = item['annotation']\n",
        "                annotation_count += 1\n",
        "\n",
        "            data_list.append(tweet_info)\n",
        "\n",
        "data_list[0:1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-9ebe1b0ea74c>:7: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  pd.set_option('display.max_colwidth', -1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Corpus': 'ALM',\n",
              "  'tweet_id': '521033092132503552',\n",
              "  'tweet_text': '@fergusonoctober @FOX2now #AllLivesMatter Peace and Love Prevail. God Bless.\\n',\n",
              "  'annotation_0': 'care',\n",
              "  'annotation_1': 'care,purity',\n",
              "  'annotation_2': 'care,purity',\n",
              "  'annotation_3': 'care',\n",
              "  'annotation_4': '',\n",
              "  'annotation_5': '',\n",
              "  'annotation_6': '',\n",
              "  'annotation_7': ''}]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnfEzEOjTH76"
      },
      "source": [
        "**1. Annotation Agreement**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0um2lWI7TFzz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "23d10144-2d69-4aa8-b37a-17b475939918"
      },
      "source": [
        "# transfer data_list to dataframe\n",
        "df = pd.DataFrame(data_list)\n",
        "\n",
        "# annotation agreement\n",
        "df1 = df.replace(r'^\\s*$', np.nan, regex=True)\n",
        "\n",
        "df1['annotation_n'] = df1.loc[:, 'annotation_0':'annotation_7'].apply(lambda x: x.notna().sum(), axis=1)\n",
        "\n",
        "# count for each type of annotation\n",
        "df1['annotation_all'] = df1[df1.columns[3:11]].apply(\n",
        "    lambda x: ','.join(x.dropna().astype(str)),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "words = ['care', 'harm', 'fairness', 'cheating', 'loyalty','betrayal','authority', 'subversion', 'purity', 'degradation', 'non-moral']\n",
        "df2 = df1.annotation_all.str.extractall('({})'.format('|'.join(words)))\\\n",
        "                           .iloc[:, 0].str.get_dummies().sum(level=0)\n",
        "\n",
        "df = pd.merge(df1, df2, left_index=True, right_index=True)\n",
        "\n",
        "# major annotation(s)\n",
        "df.loc[:,'authority':'subversion'] = df.loc[:,'authority':'subversion'].div(df.annotation_n,0)\n",
        "\n",
        "# as df.ge should running with int, using sub_df to extract int columns\n",
        "sub_df = df.loc[:,'authority':'subversion']\n",
        "df3 = pd.DataFrame(sub_df.ge(0.501).T.agg(lambda x: sub_df.columns[x].tolist()))\n",
        "df3.rename(columns={0:'annotation_main'},inplace=True)\n",
        "df3.annotation_main= df3.annotation_main.str.join(',')\n",
        "\n",
        "df = pd.merge(df, df3, left_index=True, right_index=True)\n",
        "df.head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Corpus            tweet_id  \\\n",
              "0  ALM    521033092132503552   \n",
              "\n",
              "                                                                       tweet_text  \\\n",
              "0  @fergusonoctober @FOX2now #AllLivesMatter Peace and Love Prevail. God Bless.\\n   \n",
              "\n",
              "  annotation_0 annotation_1 annotation_2 annotation_3 annotation_4  \\\n",
              "0  care         care,purity  care,purity  care         NaN           \n",
              "\n",
              "  annotation_5 annotation_6  ... care  cheating degradation  fairness  harm  \\\n",
              "0  NaN          NaN          ...  1.0  0.0       0.0         0.0       0.0    \n",
              "\n",
              "   loyalty  non-moral  purity  subversion  annotation_main  \n",
              "0  0.0      0.0        0.5     0.0         care             \n",
              "\n",
              "[1 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-97ca81ff-cf10-486c-acea-b142b69e447f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Corpus</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>annotation_0</th>\n",
              "      <th>annotation_1</th>\n",
              "      <th>annotation_2</th>\n",
              "      <th>annotation_3</th>\n",
              "      <th>annotation_4</th>\n",
              "      <th>annotation_5</th>\n",
              "      <th>annotation_6</th>\n",
              "      <th>...</th>\n",
              "      <th>care</th>\n",
              "      <th>cheating</th>\n",
              "      <th>degradation</th>\n",
              "      <th>fairness</th>\n",
              "      <th>harm</th>\n",
              "      <th>loyalty</th>\n",
              "      <th>non-moral</th>\n",
              "      <th>purity</th>\n",
              "      <th>subversion</th>\n",
              "      <th>annotation_main</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ALM</td>\n",
              "      <td>521033092132503552</td>\n",
              "      <td>@fergusonoctober @FOX2now #AllLivesMatter Peace and Love Prevail. God Bless.\\n</td>\n",
              "      <td>care</td>\n",
              "      <td>care,purity</td>\n",
              "      <td>care,purity</td>\n",
              "      <td>care</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>care</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 25 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97ca81ff-cf10-486c-acea-b142b69e447f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-97ca81ff-cf10-486c-acea-b142b69e447f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-97ca81ff-cf10-486c-acea-b142b69e447f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VI1RUP4hTKrk"
      },
      "source": [
        "**2. Text Pre-processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJa90dJZTPBo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "79ee40da-f70c-426a-fdfa-4a547e2ae8dc"
      },
      "source": [
        "# text Cleaning\n",
        "import string\n",
        "from html.parser import HTMLParser\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.tokenize import WordPunctTokenizer, word_tokenize\n",
        "\n",
        "# hashtags check\n",
        "hash_list = df.tweet_text.str.extractall(\n",
        "    r'(\\#\\w+)'\n",
        ").reset_index().drop_duplicates(['level_0', 0])[0].value_counts()\n",
        "\n",
        "split_adhere_dic = {\n",
        "    \"weve\": \"we have\", \"Weve\": \"We have\",\n",
        "    \"youve\": \"you have\", \"Youve\": \"You have\",\n",
        "    \"theyve\": \"they have\", \"Theyve\": \"They have\",\n",
        "    \"Ive\": \"I have\",\n",
        "    \"youre\": \"you are\", \"Youre\": \"You are\",\n",
        "    \"theyre\": \"they are\", \"Theyre\": \"They are\",\n",
        "    \"Im\": \"I am\", \"Ill\": \"I will\", \"Id\": \"I would\",\n",
        "    \"hes\": \"he's\", \"Hes\": \"He's\",\n",
        "    \"shes\": \"she's\", \"Shes\": \"She's\",\n",
        "    \"thats\": \"that is\", \"Thats\": \"That is\",\n",
        "    \"thatd\": \"that would\", \"Thatd\": \"That would\",\n",
        "    \"theres\": \"there is\", \"Theres\": \"There is\",\n",
        "    \"thered\": \"there would\", \"Thered\": \"There would\",\n",
        "    \"heres\": \"here is\", \"Heres\": \"Here is\",\n",
        "    # negation cues\n",
        "    \"isn't\": \"is not\", \"isnt\": \"is not\",\n",
        "    \"ain't\": \"are not\", \"aint\": \"are not\",\n",
        "    \"aren't\": \"are not\", \"arent\": \"are not\",\n",
        "    \"weren't\": \"were not\", \"werent\": \"were not\",\n",
        "    \"wasn't\": \"was not\", \"wasnt\": \" was not\",\n",
        "    \"cannot\": \"can not\", \"can't\": \" can not\", \"cant\": \" can not\",\n",
        "    \"couldn't\": \"could not\", \"couldnt\": \" could not\",\n",
        "    \"wouldn't\": \"would not\", \"wouldnt\": \"would not\",\n",
        "    \"don't\": \"do not\", \"dont\": \"do not\",\n",
        "    \"doesn't\": \"does not\", \"doesnt\": \"does not\",\n",
        "    \"didn't\": \"did not\", \"didnt\": \"did not\",\n",
        "    \"haven't\": \"have not\", \"havent\": \"have not\", \"havnt\": \"have not\",\n",
        "    \"hasn't\": \"has not\", \"hasnt\": \"has not\",\n",
        "    \"hadn't\": \"had not\", \"hadnt\": \"had not\",\n",
        "    \"shouldn't\": \"should not\", \"shouldnt\": \"should not\",\n",
        "    \"won't\": \"will not\", \"wont\": \"will not\",\n",
        "    \"mightn't\": \"might not\", \"mightnt\": \"might not\",\n",
        "    \"mustn't\": \"must not\", \"mustnt\": \"must not\",\n",
        "    \"needn't\": \"need not\", \"neednt\": \"need not\"\n",
        "    }\n",
        "\n",
        "pat1 = r'@[\\w_]+'\n",
        "pat2 = r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+'\n",
        "pat3 = r'#'\n",
        "pat3b = r'#.'\n",
        "pat4 = r'www.[^ ]+'\n",
        "pat5 = r'\\n'\n",
        "pat6= r'\\xa0'\n",
        "pat7= r'AT_USER'\n",
        "pat8 = r'pic.twitter.com/(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+'\n",
        "pat9 = r'.twitter.com/(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+'\n",
        "combined_pat = r'|'.join((pat1, pat2, pat3, pat3b, pat4, pat5, pat6, pat7, pat8, pat9))\n",
        "\n",
        "split_pattern = re.compile(r'\\b(' + '|'.join(split_adhere_dic.keys()) + r')\\b')\n",
        "\n",
        "def tweet_cleaner(demo):\n",
        "    soup = BeautifulSoup(demo, 'lxml')\n",
        "    souped = soup.get_text()\n",
        "    stripped = re.sub(combined_pat, '', souped)\n",
        "    splitted = re.sub(r\"([a-z\\.!?])([A-Z])\", r\"\\1 \\2\", stripped)\n",
        "    split_handled = split_pattern.sub(lambda x: split_adhere_dic[x.group()], splitted)\n",
        "\n",
        "    return split_handled\n",
        "\n",
        "df['new_clean_text'] = [tweet_cleaner(t) for t in df.tweet_text]\n",
        "\n",
        "# Remove stopwords/punctuations/numbers\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Add words that aren't in the NLTK stopwords list and are frequently used in MFT\n",
        "new_stopwords = ['could', 'would', 'day', 'days', 'month', 'months', 'year', 'years',\n",
        "                 'say', 'says', 'said', 'saying', 'gotta', 'wanna', 'etc']\n",
        "new_stopwords_list = stop_words.union(new_stopwords)\n",
        "\n",
        "# Negation Scope Detection for Twitter Sentiment Analysis (Reitan et al, 2015)\n",
        "not_stopwords = {'no', 'not', 'nor', 'none', 'neither', 'never', 'nothing'}\n",
        "final_stop_words = set([word for word in new_stopwords_list if word not in not_stopwords])\n",
        "\n",
        "table = str.maketrans('', '', string.punctuation)\n",
        "\n",
        "def text_process(deep):\n",
        "    words = re.split(r'\\W+', deep)\n",
        "    nopunc = [w.translate(table) for w in words]\n",
        "    nostop =  ' '.join([word for word in nopunc if word.lower() not in final_stop_words])\n",
        "    nonum = ' '.join([word for word in str(nostop).split() if not word.isdigit()])\n",
        "    return nonum\n",
        "\n",
        "df['new_clean_text_deep'] = df.apply(lambda row: text_process(row.new_clean_text), axis=1)\n",
        "\n",
        "# Stemming words\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "porter_stemmer = PorterStemmer()\n",
        "\n",
        "def stem_sentences(sentence):\n",
        "    tokens = sentence.split()\n",
        "    stemmed_tokens = [porter_stemmer.stem(token) for token in tokens]\n",
        "    return ' '.join(stemmed_tokens)\n",
        "\n",
        "df['new_clean_text_deep_stem'] = df['new_clean_text_deep'].apply(stem_sentences)\n",
        "df.head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Corpus            tweet_id  \\\n",
              "0  ALM    521033092132503552   \n",
              "\n",
              "                                                                       tweet_text  \\\n",
              "0  @fergusonoctober @FOX2now #AllLivesMatter Peace and Love Prevail. God Bless.\\n   \n",
              "\n",
              "  annotation_0 annotation_1 annotation_2 annotation_3 annotation_4  \\\n",
              "0  care         care,purity  care,purity  care         NaN           \n",
              "\n",
              "  annotation_5 annotation_6  ... fairness  harm loyalty  non-moral  purity  \\\n",
              "0  NaN          NaN          ...  0.0      0.0   0.0     0.0        0.5      \n",
              "\n",
              "   subversion  annotation_main  \\\n",
              "0  0.0         care              \n",
              "\n",
              "                                          new_clean_text  \\\n",
              "0    All Lives Matter Peace and Love Prevail. God Bless.   \n",
              "\n",
              "                         new_clean_text_deep  \\\n",
              "0  Lives Matter Peace Love Prevail God Bless   \n",
              "\n",
              "                  new_clean_text_deep_stem  \n",
              "0  live matter peac love prevail god bless  \n",
              "\n",
              "[1 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af9a08ce-745d-4834-888a-1aaaee961a20\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Corpus</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>annotation_0</th>\n",
              "      <th>annotation_1</th>\n",
              "      <th>annotation_2</th>\n",
              "      <th>annotation_3</th>\n",
              "      <th>annotation_4</th>\n",
              "      <th>annotation_5</th>\n",
              "      <th>annotation_6</th>\n",
              "      <th>...</th>\n",
              "      <th>fairness</th>\n",
              "      <th>harm</th>\n",
              "      <th>loyalty</th>\n",
              "      <th>non-moral</th>\n",
              "      <th>purity</th>\n",
              "      <th>subversion</th>\n",
              "      <th>annotation_main</th>\n",
              "      <th>new_clean_text</th>\n",
              "      <th>new_clean_text_deep</th>\n",
              "      <th>new_clean_text_deep_stem</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ALM</td>\n",
              "      <td>521033092132503552</td>\n",
              "      <td>@fergusonoctober @FOX2now #AllLivesMatter Peace and Love Prevail. God Bless.\\n</td>\n",
              "      <td>care</td>\n",
              "      <td>care,purity</td>\n",
              "      <td>care,purity</td>\n",
              "      <td>care</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>care</td>\n",
              "      <td>All Lives Matter Peace and Love Prevail. God Bless.</td>\n",
              "      <td>Lives Matter Peace Love Prevail God Bless</td>\n",
              "      <td>live matter peac love prevail god bless</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 28 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af9a08ce-745d-4834-888a-1aaaee961a20')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-af9a08ce-745d-4834-888a-1aaaee961a20 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-af9a08ce-745d-4834-888a-1aaaee961a20');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH4trqITg3bd"
      },
      "source": [
        "# remove substring which conains numbers\n",
        "df.new_clean_text_deep_stem = df.new_clean_text_deep_stem.str.replace('[\\w_]+\\d+[\\w_]+', ' ')\n",
        "df.new_clean_text_deep_stem = df.new_clean_text_deep_stem.str.replace('\\d+[\\w_]+', ' ')\n",
        "df.new_clean_text_deep_stem = df.new_clean_text_deep_stem.str.replace('[\\w_]+\\d+', ' ')\n",
        "\n",
        "l = [\"sandi\", \"nyc\", \" NY \", \"blm\", \" url\", \" http\", \" htt \", \" via\", \" ppl \", \" pic \", \"baltimor\",\n",
        "     \" Dr \", \" Mr \", \" Sr \", \" AL \", \" TL \", \" CA \", \" AP \", \" AC \", \" PD \", \" NJ \", \" JK \",\n",
        "     \" MC \", \" AR \", \" PA \", \" KU \", \" AG \", \" NE \", \" MN \", \" SE \", \" BM \", \" BW \", \" EI \",\n",
        "     \" DC \", \" OT \", \" GO \", \" LA \", \" CK \", \" EC \", \" SA \", \" MT \", \" BS \", \" DE \", \" KS \",\n",
        "     \" QB \", \" LE \", \" OA \", \" PA \", \" DJ \", \" DM \", \" WH \", \" OI \", \" ST \", \" AG \", \" SC \",\n",
        "     \" GT \", \" MS \", \" CD \", \" VO \", \" BI \", \" ET \", \" AH \", \" NW \", \" RP \", \" Go \", \" CE \",\n",
        "     \" Oh \", \" OH \", \" FL \", \" BA \", \" FU \", \" YO \", \" GS \", \" BO \", \" BC \", \" VA \", \" BT \",\n",
        "     \" LX \", \" DA \", \" EN \", \" HT \", \" AW \", \" Co \", \" PD \", \" SA \", \" OD \", \" NE \", \" XI \",\n",
        "     \" u \", \" c \", \" d \", \" a \", \" b \", \" t \", \" k \", \" m \", \" v \", \" n \", \" r \", \" w \",\n",
        "     \" aa \", \" cc \", \" kkk\", \" ur \", \" fr \", \" ya \", \" tf \", \" fb \", \" stfu \",\n",
        "     \" N \", \" F \", \" K \", \" B \", \" J \", \" Z \", \" H \", \" R \", \" U \", \" E \", \" P \", \" W \", \" Q \", \" G \", \" L \", \" I \",\n",
        "     \"uddfa\", \"uddef\", \"uddeb\", \"udffb\", \"udffd\", \"udffb\", \"udffc\", \"udde\", \"udcaf\", \"udcaaladi\", \"udcfa\", \"uddf\", \"udcaa\",\n",
        "     \" th \", \" nd \", \" am \", \" pm \", \" kg \", \" hr \", \"et al\",\n",
        "     \"Ù\", \"Ü\", \"Û\", \"û\", \"û\", \"â\", \"å\", \"è\", \"Ç\", \"Ï\", \"ï\", \"ā\", \"ª\", \"Ó\", \"Ð\", \"Õ\", \"ù\"]\n",
        "\n",
        "df.new_clean_text_deep_stem = df.new_clean_text_deep_stem.str.replace('|'.join(l), ' ', regex=True).str.strip().replace(' ', '')\n",
        "\n",
        "#df.to_excel('output_for_R_050_use.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}